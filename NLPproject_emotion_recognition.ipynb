{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPproject_emotion_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/Projects-kaggle-problems-60daysofudacity/blob/master/NLPproject_emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgDvFNfInAKY",
        "colab_type": "text"
      },
      "source": [
        "# Project : NLP Emotion recognition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKe37pq4nH0k",
        "colab_type": "text"
      },
      "source": [
        "## Importing all the packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGCvGqgNOPAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "import torch.utils.data as data_utils\n",
        "from PIL import Image, ImageFile\n",
        "import json\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXJZHqKAjTLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uiC_l_9nM7D",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXhyhZsgjZ3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GzeUNKZlENi",
        "colab_type": "code",
        "outputId": "50deb51d-1be7-47a2-9c2e-318104ad986a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2L6wF2mPVc",
        "colab_type": "code",
        "outputId": "f761ebb1-aca9-42ed-aaa2-ae977e9befa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# load data\n",
        "text_data = load_from_pickle(directory=\"/content/drive/My Drive/train.pkl\")\n",
        "text_data.emotion.value_counts().plot.bar()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f070edb8cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEbCAYAAAAxukhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMXfE6ylmf2n",
        "colab_type": "code",
        "outputId": "84d1aee7-3f4d-4cf8-f56a-ae747dd483b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "text_data.head(10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>how the fu k who the heck moved my fridge shou...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>so my indian uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>uk i asked for my parcel to be delivered to a ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>don t join they put the phone down on you talk...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10005</td>\n",
              "      <td>my blood is boiling</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10006</td>\n",
              "      <td>when you ve still got a whole season of wentwo...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10007</td>\n",
              "      <td>uk why does tracking show my equipment deliver...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10008</td>\n",
              "      <td>legit why i am so furious with him people are ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10009</td>\n",
              "      <td>how is it suppose to work if you do that wtf d...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                             tweets emotion  intensity\n",
              "0  10000  how the fu k who the heck moved my fridge shou...   anger      0.938\n",
              "1  10001  so my indian uber driver just called someone t...   anger      0.896\n",
              "2  10002  uk i asked for my parcel to be delivered to a ...   anger      0.896\n",
              "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
              "4  10004  don t join they put the phone down on you talk...   anger      0.896\n",
              "5  10005                                my blood is boiling   anger      0.875\n",
              "6  10006  when you ve still got a whole season of wentwo...   anger      0.875\n",
              "7  10007  uk why does tracking show my equipment deliver...   anger      0.875\n",
              "8  10008  legit why i am so furious with him people are ...   anger      0.875\n",
              "9  10009  how is it suppose to work if you do that wtf d...   anger      0.875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGbqP_dm5zV",
        "colab_type": "code",
        "outputId": "0283b66f-157e-46f0-e446-dfe933a50594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_data.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46969, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo8fJ80eiB8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55be030d-1083-4cee-e938-7e3001e3b856"
      },
      "source": [
        "len(text_data['tweets'][0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KX8YfRqmSn0",
        "colab_type": "code",
        "outputId": "d5679027-54e1-4dee-f0cb-0907e52eef53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vAXfjJBah40",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yha3oqZLxJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data[\"token_size\"] = text_data[\"tweets\"].apply(lambda x: len(x.split(' ')))\n",
        "text_data = text_data.loc[text_data['token_size'] < 70].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b-Nn5wxOCvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_list = text_data[\"tweets\"].values.tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxWQGibPLRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for i in words_list:\n",
        "  words.append(nltk.word_tokenize(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEfK-gBrapL0",
        "colab_type": "text"
      },
      "source": [
        "## Constructing dictionery for mapping words to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRMYPdvU6sv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEUq5i6SYzWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = ConstructVocab(words_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEgzoprWY_KB",
        "colab_type": "code",
        "outputId": "0a9611ff-a688-4f8c-8233-2dc11eb27136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "inputs.vocab[0:10]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaron',\n",
              " 'aateam',\n",
              " 'ab',\n",
              " 'abby',\n",
              " 'aber',\n",
              " 'aberdeen',\n",
              " 'abhijit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvRJVJ26Zbcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in words_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JUBnUBO-ISd",
        "colab_type": "code",
        "outputId": "c85424a5-f057-4d59-8282-ad26b401ff0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3420,\n",
              "  7358,\n",
              "  2781,\n",
              "  3870,\n",
              "  8087,\n",
              "  7358,\n",
              "  3269,\n",
              "  4695,\n",
              "  4748,\n",
              "  2750,\n",
              "  6602,\n",
              "  3479,\n",
              "  3968,\n",
              "  7358,\n",
              "  4012,\n",
              "  2033,\n",
              "  280,\n",
              "  4308],\n",
              " [6770,\n",
              "  4748,\n",
              "  3582,\n",
              "  7672,\n",
              "  2080,\n",
              "  3859,\n",
              "  1054,\n",
              "  6807,\n",
              "  7358,\n",
              "  4755,\n",
              "  8170,\n",
              "  3503,\n",
              "  3479,\n",
              "  7977,\n",
              "  7203,\n",
              "  3557,\n",
              "  1,\n",
              "  4701,\n",
              "  7831,\n",
              "  3479,\n",
              "  1698,\n",
              "  3226,\n",
              "  3847,\n",
              "  5233,\n",
              "  1955]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ByE4kkEnwD",
        "colab_type": "code",
        "outputId": "295c115a-ba21-4add-f254-382606befc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)  "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knxytlIvFNUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHjSBwAWHuBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KzVKg9xHw5a",
        "colab_type": "code",
        "outputId": "233a1362-86d5-41fa-d99c-53f87994f7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3420, 7358, 2781, 3870, 8087, 7358, 3269, 4695, 4748, 2750, 6602,\n",
              "        3479, 3968, 7358, 4012, 2033,  280, 4308,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " array([6770, 4748, 3582, 7672, 2080, 3859, 1054, 6807, 7358, 4755, 8170,\n",
              "        3503, 3479, 7977, 7203, 3557,    1, 4701, 7831, 3479, 1698, 3226,\n",
              "        3847, 5233, 1955,    0,    0,    0,    0,    0,    0,    0,    0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFwGF1aH0a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(text_data.emotion.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in text_data[['emotion']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXgb1DZCM6iS",
        "colab_type": "code",
        "outputId": "353a4422-ad2b-4e01-8358-ebd53fd0d790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "target_tensor"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjBJ4ZxsM-sp",
        "colab_type": "code",
        "outputId": "7b1b20d4-9645-46c6-a373-e0d75cff77fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "text_data[0:3]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>how the fu k who the heck moved my fridge shou...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>so my indian uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>uk i asked for my parcel to be delivered to a ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... token_size\n",
              "0  10000  ...         18\n",
              "1  10001  ...         25\n",
              "2  10002  ...         19\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ljb1Jyu9ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e220665f-af43-47f2-f5ce-71694176e1a2"
      },
      "source": [
        "text_data[\"emotion\"]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        anger\n",
              "1        anger\n",
              "2        anger\n",
              "3        anger\n",
              "4        anger\n",
              "5        anger\n",
              "6        anger\n",
              "7        anger\n",
              "8        anger\n",
              "9        anger\n",
              "10       anger\n",
              "11       anger\n",
              "12       anger\n",
              "13       anger\n",
              "14       anger\n",
              "15       anger\n",
              "16       anger\n",
              "17       anger\n",
              "18       anger\n",
              "19       anger\n",
              "20       anger\n",
              "21       anger\n",
              "22       anger\n",
              "23       anger\n",
              "24       anger\n",
              "25       anger\n",
              "26       anger\n",
              "27       anger\n",
              "28       anger\n",
              "29       anger\n",
              "         ...  \n",
              "46939      joy\n",
              "46940      joy\n",
              "46941      joy\n",
              "46942      joy\n",
              "46943      joy\n",
              "46944      joy\n",
              "46945      joy\n",
              "46946      joy\n",
              "46947      joy\n",
              "46948      joy\n",
              "46949      joy\n",
              "46950      joy\n",
              "46951      joy\n",
              "46952      joy\n",
              "46953      joy\n",
              "46954      joy\n",
              "46955      joy\n",
              "46956      joy\n",
              "46957      joy\n",
              "46958      joy\n",
              "46959      joy\n",
              "46960      joy\n",
              "46961      joy\n",
              "46962      joy\n",
              "46963      joy\n",
              "46964      joy\n",
              "46965      joy\n",
              "46966      joy\n",
              "46967      joy\n",
              "46968      joy\n",
              "Name: emotion, Length: 46969, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKLK_kptNJQg",
        "colab_type": "code",
        "outputId": "3ab80a94-1be5-45be-bfa0-575efd8f6f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)\n",
        "get_emotion(target_tensor[1])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kksj7uiWNOQr",
        "colab_type": "code",
        "outputId": "8bcfc010-0b4c-4812-a2c9-39223c5cb4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'sadness', 3: 'joy'}\n",
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anger'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFQoAnj3NTd0",
        "colab_type": "code",
        "outputId": "a7ebd4d1-e5d1-4b87-8bd8-af01fc564549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "print(f\"training length: {len(input_tensor_train)}\")\n",
        "print(f\"training target length: {len(target_tensor_train)}\")\n",
        "print(f\"validation length: {len(input_tensor_val)}\")\n",
        "print(f\"validation target length: {len(target_tensor_val)}\")\n",
        "print(f\"testing length: {len(input_tensor_test)}\")\n",
        "print(f\"testing target length: {len(target_tensor_test)}\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training length: 37575\n",
            "training target length: 37575\n",
            "validation length: 4697\n",
            "validation target length: 4697\n",
            "testing length: 4697\n",
            "testing target length: 4697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-tVlL-fNlCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RI8tBbiNuo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su-O_-rqNxt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeQ295U9PwKq",
        "colab_type": "code",
        "outputId": "6e8fdcaa-9dad-4578-afe6-c739cec8684f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_dataset))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dNY4N2rNz0p",
        "colab_type": "code",
        "outputId": "1af62b50-8939-4035-b230-34cfa89119b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYpzu73nN2Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1miHD3PN5gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39jqITmtN8WZ",
        "colab_type": "code",
        "outputId": "18545934-718a-43b3-a7ea-aa8319e98404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(\"Output size : \", output.size())\n",
        "print(device)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([33, 64])\n",
            "Output size :  torch.Size([64, 4])\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPOMgqw_N-aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClyQJ9QsOB6O",
        "colab_type": "code",
        "outputId": "7eec88da-d231-47fe-852f-7c9af9704f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.0069\n",
            "Epoch 1 Batch 100 Val. Loss 0.0076\n",
            "Epoch 1 Batch 200 Val. Loss 0.0026\n",
            "Epoch 1 Batch 300 Val. Loss 0.0120\n",
            "Epoch 1 Batch 400 Val. Loss 0.0077\n",
            "Epoch 1 Batch 500 Val. Loss 0.0134\n",
            "Epoch 1 Loss 0.0122 -- Train Acc. 97.0000 -- Val Acc. 97.0000\n",
            "Time taken for 1 epoch 25.748496770858765 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.0056\n",
            "Epoch 2 Batch 100 Val. Loss 0.0006\n",
            "Epoch 2 Batch 200 Val. Loss 0.0115\n",
            "Epoch 2 Batch 300 Val. Loss 0.0281\n",
            "Epoch 2 Batch 400 Val. Loss 0.0002\n",
            "Epoch 2 Batch 500 Val. Loss 0.0144\n",
            "Epoch 2 Loss 0.0082 -- Train Acc. 98.0000 -- Val Acc. 97.0000\n",
            "Time taken for 1 epoch 25.93695640563965 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.0046\n",
            "Epoch 3 Batch 100 Val. Loss 0.0001\n",
            "Epoch 3 Batch 200 Val. Loss 0.0001\n",
            "Epoch 3 Batch 300 Val. Loss 0.0030\n",
            "Epoch 3 Batch 400 Val. Loss 0.0051\n",
            "Epoch 3 Batch 500 Val. Loss 0.0324\n",
            "Epoch 3 Loss 0.0102 -- Train Acc. 97.0000 -- Val Acc. 97.0000\n",
            "Time taken for 1 epoch 26.151772022247314 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0284\n",
            "Epoch 4 Batch 100 Val. Loss 0.0059\n",
            "Epoch 4 Batch 200 Val. Loss 0.0001\n",
            "Epoch 4 Batch 300 Val. Loss 0.0246\n",
            "Epoch 4 Batch 400 Val. Loss 0.0076\n",
            "Epoch 4 Batch 500 Val. Loss 0.0002\n",
            "Epoch 4 Loss 0.0079 -- Train Acc. 98.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.29914116859436 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0002\n",
            "Epoch 5 Batch 100 Val. Loss 0.0379\n",
            "Epoch 5 Batch 200 Val. Loss 0.0309\n",
            "Epoch 5 Batch 300 Val. Loss 0.0057\n",
            "Epoch 5 Batch 400 Val. Loss 0.0002\n",
            "Epoch 5 Batch 500 Val. Loss 0.0002\n",
            "Epoch 5 Loss 0.0085 -- Train Acc. 98.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.332956075668335 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0158\n",
            "Epoch 6 Batch 100 Val. Loss 0.0078\n",
            "Epoch 6 Batch 200 Val. Loss 0.0150\n",
            "Epoch 6 Batch 300 Val. Loss 0.0034\n",
            "Epoch 6 Batch 400 Val. Loss 0.0164\n",
            "Epoch 6 Batch 500 Val. Loss 0.0138\n",
            "Epoch 6 Loss 0.0072 -- Train Acc. 98.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.281362056732178 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0023\n",
            "Epoch 7 Batch 100 Val. Loss 0.0005\n",
            "Epoch 7 Batch 200 Val. Loss 0.0007\n",
            "Epoch 7 Batch 300 Val. Loss 0.0076\n",
            "Epoch 7 Batch 400 Val. Loss 0.0295\n",
            "Epoch 7 Batch 500 Val. Loss 0.0111\n",
            "Epoch 7 Loss 0.0078 -- Train Acc. 98.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.299800872802734 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0044\n",
            "Epoch 8 Batch 100 Val. Loss 0.0186\n",
            "Epoch 8 Batch 200 Val. Loss 0.0235\n",
            "Epoch 8 Batch 300 Val. Loss 0.0255\n",
            "Epoch 8 Batch 400 Val. Loss 0.0114\n",
            "Epoch 8 Batch 500 Val. Loss 0.0145\n",
            "Epoch 8 Loss 0.0080 -- Train Acc. 98.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.25537943840027 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0192\n",
            "Epoch 9 Batch 100 Val. Loss 0.0146\n",
            "Epoch 9 Batch 200 Val. Loss 0.0063\n",
            "Epoch 9 Batch 300 Val. Loss 0.0127\n",
            "Epoch 9 Batch 400 Val. Loss 0.0002\n",
            "Epoch 9 Batch 500 Val. Loss 0.0002\n",
            "Epoch 9 Loss 0.0132 -- Train Acc. 97.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.300461769104004 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0075\n",
            "Epoch 10 Batch 100 Val. Loss 0.0007\n",
            "Epoch 10 Batch 200 Val. Loss 0.0040\n",
            "Epoch 10 Batch 300 Val. Loss 0.0335\n",
            "Epoch 10 Batch 400 Val. Loss 0.0162\n",
            "Epoch 10 Batch 500 Val. Loss 0.0058\n",
            "Epoch 10 Loss 0.0079 -- Train Acc. 98.0000 -- Val Acc. 98.0000\n",
            "Time taken for 1 epoch 26.31150984764099 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEm63ZmhrNET",
        "colab_type": "code",
        "outputId": "20030c50-7b39-4bb8-b166-2aad89f118c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(8347, 256)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVNldRc_6GW",
        "colab_type": "code",
        "outputId": "8ccac11e-0395-4cc6-caf6-1f795e61ebd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  98.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}