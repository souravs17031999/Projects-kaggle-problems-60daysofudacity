{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPproject_emotion_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/Projects-kaggle-problems-60daysofudacity/blob/master/NLPproject_emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgDvFNfInAKY",
        "colab_type": "text"
      },
      "source": [
        "# Project : NLP Emotion recognition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKe37pq4nH0k",
        "colab_type": "text"
      },
      "source": [
        "## Importing all the packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGCvGqgNOPAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "import torch.utils.data as data_utils\n",
        "from PIL import Image, ImageFile\n",
        "import json\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXJZHqKAjTLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uiC_l_9nM7D",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXhyhZsgjZ3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GzeUNKZlENi",
        "colab_type": "code",
        "outputId": "9225cd5b-9ac3-45d8-a1d6-83b6425edd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2L6wF2mPVc",
        "colab_type": "code",
        "outputId": "18020e09-9d7e-4b76-ad83-1806e1d6bfb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# load data\n",
        "text_data = load_from_pickle(directory=\"/content/drive/My Drive/merged_training.pkl\")\n",
        "text_data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efbc5d18d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHDBJREFUeJzt3X2UHXWd5/H3x2SCoDwE6WExiSZq\nBjfiE0bILs4OCwpB0DCKDoyarBPJWYXRcd2R4OjEg7IHH47sMKNZA4kE1yEgzkhGgjGDouNDgAYZ\nMCCmiSDJgokEiUcGIcxn/6hfw02nHyp9b7o63Z/XOfd01a9+detb0OnPrapf1ZVtIiIi6nhW0wVE\nRMS+I6ERERG1JTQiIqK2hEZERNSW0IiIiNoSGhERUVtCIyIiaktoREREbQmNiIioLaERERG1TWy6\ngE477LDDPH369KbLiIjYp9x6662/st01VL8xFxrTp0+nu7u76TIiIvYpku6v0y+npyIioraERkRE\n1JbQiIiI2hIaERFRW0IjIiJqS2hERERtQ4aGpBWStkr6ST/LPiTJkg4r85J0iaQeSXdIOrql7wJJ\nG8trQUv7ayTdWda5RJJK+6GS1pX+6yRN7swuR0TEcNU50rgcmNu3UdI04CTgFy3NpwAzy2sRsLT0\nPRRYAhwLHAMsaQmBpcDZLev1bmsxcIPtmcANZT4iIho05M19tr8naXo/iy4GPgxc29I2D7jCtoH1\nkg6RdARwPLDO9nYASeuAuZJuBA6yvb60XwGcDlxf3uv48r4rgRuB8/Zo7/bA9MXX7a237td9F506\notuLiOiEYV3TkDQP2GL7X/ssmgI80DK/ubQN1r65n3aAw20/WKYfAg4fTq0REdE5e/wYEUkHAB+h\nOjU1ImxbkgepaRHV6TBe8IIXjFRZERHjznCONF4MzAD+VdJ9wFTgNkn/AdgCTGvpO7W0DdY+tZ92\ngF+WU1uUn1sHKsj2Mtuzbc/u6hryeVsRETFMexwatu+0/fu2p9ueTnVK6WjbDwGrgfllFNUc4NFy\nimktcJKkyeUC+EnA2rJsh6Q5ZdTUfJ65RrIa6B1ltYBdr51EREQD6gy5vRL4EXCkpM2SFg7SfQ2w\nCegBLgXeB1AugH8CuKW8Lui9KF76XFbWuZfqIjjARcAbJG0EXl/mIyKiQXVGT501xPLpLdMGzhmg\n3wpgRT/t3cBR/bQ/DJw4VH0RETFyckd4RETUltCIiIjaEhoREVFbQiMiImpLaERERG0JjYiIqC2h\nERERtSU0IiKitoRGRETUltCIiIjaEhoREVFbQiMiImpLaERERG0JjYiIqC2hERERtSU0IiKitoRG\nRETUltCIiIjaEhoREVFbQiMiImobMjQkrZC0VdJPWto+I+mnku6Q9I+SDmlZdr6kHkn3SDq5pX1u\naeuRtLilfYakm0r7VZImlfb9ynxPWT69UzsdERHDU+dI43Jgbp+2dcBRtl8B/Aw4H0DSLOBM4GVl\nnS9ImiBpAvB54BRgFnBW6QvwKeBi2y8BHgEWlvaFwCOl/eLSLyIiGjRxqA62v9f3U77tb7XMrgfO\nKNPzgFW2fwf8XFIPcExZ1mN7E4CkVcA8SXcDJwB/WvqsBD4OLC3v9fHSfg3wd5Jk23uwf1FMX3zd\niG7vvotOHdHtRcTI6MQ1jT8Dri/TU4AHWpZtLm0DtT8P+LXtnX3ad3mvsvzR0j8iIhrSVmhI+itg\nJ/CVzpQz7DoWSeqW1L1t27YmS4mIGNOGHRqS/htwGvCOllNGW4BpLd2mlraB2h8GDpE0sU/7Lu9V\nlh9c+u/G9jLbs23P7urqGu4uRUTEEIYVGpLmAh8G3mz7sZZFq4Ezy8inGcBM4GbgFmBmGSk1iepi\n+eoSNt/hmWsiC4BrW95rQZk+A/h2rmdERDRryAvhkq4EjgcOk7QZWEI1Wmo/YJ0kgPW2/7vtDZKu\nBu6iOm11ju2nyvucC6wFJgArbG8omzgPWCXpk8CPgeWlfTnw5XIxfTtV0ERERIPqjJ46q5/m5f20\n9fa/ELiwn/Y1wJp+2jfxzAir1vbHgbcNVV9ERIyc3BEeERG1JTQiIqK2hEZERNSW0IiIiNoSGhER\nUVtCIyIiaktoREREbQmNiIioLaERERG1JTQiIqK2hEZERNSW0IiIiNoSGhERUVtCIyIiaktoRERE\nbQmNiIioLaERERG1JTQiIqK2hEZERNSW0IiIiNqGDA1JKyRtlfSTlrZDJa2TtLH8nFzaJekSST2S\n7pB0dMs6C0r/jZIWtLS/RtKdZZ1LJGmwbURERHPqHGlcDszt07YYuMH2TOCGMg9wCjCzvBYBS6EK\nAGAJcCxwDLCkJQSWAme3rDd3iG1ERERDhgwN298DtvdpngesLNMrgdNb2q9wZT1wiKQjgJOBdba3\n234EWAfMLcsOsr3etoEr+rxXf9uIiIiGDPeaxuG2HyzTDwGHl+kpwAMt/TaXtsHaN/fTPtg2IiKi\nIW1fCC9HCO5ALcPehqRFkroldW/btm1vlhIRMa4NNzR+WU4tUX5uLe1bgGkt/aaWtsHap/bTPtg2\ndmN7me3Ztmd3dXUNc5ciImIoww2N1UDvCKgFwLUt7fPLKKo5wKPlFNNa4CRJk8sF8JOAtWXZDklz\nyqip+X3eq79tREREQyYO1UHSlcDxwGGSNlONgroIuFrSQuB+4O2l+xrgjUAP8BjwbgDb2yV9Aril\n9LvAdu/F9fdRjdDaH7i+vBhkGxER0ZAhQ8P2WQMsOrGfvgbOGeB9VgAr+mnvBo7qp/3h/rYRERHN\nyR3hERFRW0IjIiJqS2hERERtCY2IiKgtoREREbUlNCIioraERkRE1JbQiIiI2hIaERFRW0IjIiJq\nS2hERERtCY2IiKgtoREREbUlNCIioraERkRE1JbQiIiI2hIaERFRW0IjIiJqS2hERERtCY2IiKgt\noREREbW1FRqSPihpg6SfSLpS0rMlzZB0k6QeSVdJmlT67lfme8ry6S3vc35pv0fSyS3tc0tbj6TF\n7dQaERHtG3ZoSJoCvB+YbfsoYAJwJvAp4GLbLwEeARaWVRYCj5T2i0s/JM0q670MmAt8QdIESROA\nzwOnALOAs0rfiIhoSLunpyYC+0uaCBwAPAicAFxTlq8ETi/T88o8ZfmJklTaV9n+ne2fAz3AMeXV\nY3uT7SeAVaVvREQ0ZNihYXsL8FngF1Rh8ShwK/Br2ztLt83AlDI9BXigrLuz9H9ea3ufdQZqj4iI\nhrRzemoy1Sf/GcDzgedQnV4acZIWSeqW1L1t27YmSoiIGBfaOT31euDntrfZfhL4B+A44JByugpg\nKrClTG8BpgGU5QcDD7e291lnoPbd2F5me7bt2V1dXW3sUkREDKad0PgFMEfSAeXaxInAXcB3gDNK\nnwXAtWV6dZmnLP+2bZf2M8voqhnATOBm4BZgZhmNNYnqYvnqNuqNiIg2TRy6S/9s3yTpGuA2YCfw\nY2AZcB2wStInS9vysspy4MuSeoDtVCGA7Q2SrqYKnJ3AObafApB0LrCWamTWCtsbhltvRES0b9ih\nAWB7CbCkT/MmqpFPffs+DrxtgPe5ELiwn/Y1wJp2aoyIiM7JHeEREVFbQiMiImpLaERERG0JjYiI\nqC2hERERtSU0IiKitoRGRETUltCIiIjaEhoREVFbQiMiImpLaERERG0JjYiIqC2hERERtSU0IiKi\ntoRGRETUltCIiIjaEhoREVFbQiMiImpLaERERG0JjYiIqK2t0JB0iKRrJP1U0t2S/pOkQyWtk7Sx\n/Jxc+krSJZJ6JN0h6eiW91lQ+m+UtKCl/TWS7izrXCJJ7dQbERHtafdI42+Ab9p+KfBK4G5gMXCD\n7ZnADWUe4BRgZnktApYCSDoUWAIcCxwDLOkNmtLn7Jb15rZZb0REtGHYoSHpYOC/AMsBbD9h+9fA\nPGBl6bYSOL1MzwOucGU9cIikI4CTgXW2t9t+BFgHzC3LDrK93raBK1reKyIiGtDOkcYMYBvwJUk/\nlnSZpOcAh9t+sPR5CDi8TE8BHmhZf3NpG6x9cz/tERHRkHZCYyJwNLDU9quB3/LMqSgAyhGC29hG\nLZIWSeqW1L1t27a9vbmIiHGrndDYDGy2fVOZv4YqRH5ZTi1Rfm4ty7cA01rWn1raBmuf2k/7bmwv\nsz3b9uyurq42dikiIgYz7NCw/RDwgKQjS9OJwF3AaqB3BNQC4NoyvRqYX0ZRzQEeLaex1gInSZpc\nLoCfBKwty3ZImlNGTc1vea+IiGjAxDbX/3PgK5ImAZuAd1MF0dWSFgL3A28vfdcAbwR6gMdKX2xv\nl/QJ4JbS7wLb28v0+4DLgf2B68srIiIa0lZo2L4dmN3PohP76WvgnAHeZwWwop/2buCodmqM8WH6\n4utGbFv3XXTqiG0rYrTJHeEREVFbQiMiImpLaERERG0JjYiIqC2hERERtSU0IiKitoRGRETUltCI\niIjaEhoREVFbQiMiImpLaERERG0JjYiIqC2hERERtbX7aPSI2MtG8gm+kKf4xuBypBEREbUlNCIi\noraERkRE1JbQiIiI2hIaERFRW0IjIiJqazs0JE2Q9GNJ3yjzMyTdJKlH0lWSJpX2/cp8T1k+veU9\nzi/t90g6uaV9bmnrkbS43VojIqI9nTjS+ABwd8v8p4CLbb8EeARYWNoXAo+U9otLPyTNAs4EXgbM\nBb5QgmgC8HngFGAWcFbpGxERDWkrNCRNBU4FLivzAk4ArildVgKnl+l5ZZ6y/MTSfx6wyvbvbP8c\n6AGOKa8e25tsPwGsKn0jIqIh7R5p/G/gw8C/l/nnAb+2vbPMbwamlOkpwAMAZfmjpf/T7X3WGag9\nIiIaMuzQkHQasNX2rR2sZ7i1LJLULal727ZtTZcTETFmtXOkcRzwZkn3UZ06OgH4G+AQSb3PtJoK\nbCnTW4BpAGX5wcDDre191hmofTe2l9mebXt2V1dXG7sUERGDGXZo2D7f9lTb06kuZH/b9juA7wBn\nlG4LgGvL9OoyT1n+bdsu7WeW0VUzgJnAzcAtwMwyGmtS2cbq4dYbERHt2xtPuT0PWCXpk8CPgeWl\nfTnwZUk9wHaqEMD2BklXA3cBO4FzbD8FIOlcYC0wAVhhe8NeqDciImrqSGjYvhG4sUxvohr51LfP\n48DbBlj/QuDCftrXAGs6UWNERLQvd4RHRERtCY2IiKgtoREREbXl614jolH5Ott9S440IiKitoRG\nRETUltCIiIjaEhoREVFbQiMiImpLaERERG0JjYiIqC2hERERtSU0IiKitoRGRETUltCIiIjaEhoR\nEVFbQiMiImpLaERERG0JjYiIqC2hERERtSU0IiKitmGHhqRpkr4j6S5JGyR9oLQfKmmdpI3l5+TS\nLkmXSOqRdIeko1vea0Hpv1HSgpb210i6s6xziSS1s7MREdGedo40dgIfsj0LmAOcI2kWsBi4wfZM\n4IYyD3AKMLO8FgFLoQoZYAlwLHAMsKQ3aEqfs1vWm9tGvRER0aZhh4btB23fVqZ/A9wNTAHmAStL\nt5XA6WV6HnCFK+uBQyQdAZwMrLO93fYjwDpgbll2kO31tg1c0fJeERHRgI5c05A0HXg1cBNwuO0H\ny6KHgMPL9BTggZbVNpe2wdo399MeERENaTs0JD0X+BrwF7Z3tC4rRwhudxs1algkqVtS97Zt2/b2\n5iIixq22QkPS71EFxlds/0Np/mU5tUT5ubW0bwGmtaw+tbQN1j61n/bd2F5me7bt2V1dXe3sUkRE\nDKKd0VMClgN32/5cy6LVQO8IqAXAtS3t88soqjnAo+U01lrgJEmTywXwk4C1ZdkOSXPKtua3vFdE\nRDRgYhvrHge8C7hT0u2l7SPARcDVkhYC9wNvL8vWAG8EeoDHgHcD2N4u6RPALaXfBba3l+n3AZcD\n+wPXl1dERDRk2KFh+/vAQPdNnNhPfwPnDPBeK4AV/bR3A0cNt8aIiOis3BEeERG1JTQiIqK2dq5p\nRETEEKYvvm5Et3ffRafu1ffPkUZERNSW0IiIiNoSGhERUVtCIyIiaktoREREbQmNiIioLaERERG1\nJTQiIqK2hEZERNSW0IiIiNoSGhERUVtCIyIiaktoREREbQmNiIioLaERERG1JTQiIqK2hEZERNQ2\n6kND0lxJ90jqkbS46XoiIsazUR0akiYAnwdOAWYBZ0ma1WxVERHj16gODeAYoMf2JttPAKuAeQ3X\nFBExbo320JgCPNAyv7m0RUREA2S76RoGJOkMYK7t95T5dwHH2j63T79FwKIyeyRwzwiWeRjwqxHc\n3kgby/s3lvcNsn/7upHevxfa7hqq08SRqKQNW4BpLfNTS9subC8Dlo1UUa0kddue3cS2R8JY3r+x\nvG+Q/dvXjdb9G+2np24BZkqaIWkScCawuuGaIiLGrVF9pGF7p6RzgbXABGCF7Q0NlxURMW6N6tAA\nsL0GWNN0HYNo5LTYCBrL+zeW9w2yf/u6Ubl/o/pCeEREjC6j/ZpGRESMIgmNiIioLaGxhyS9SVL+\nu+2DVJk2dM+IGEj++O25PwE2Svq0pJc2XczeJGmypFc0XUenuLqAN5oHVbRF0gRJP226jr1N0gsl\nvb5M7y/pwKZrGk8SGnvI9juBVwP3ApdL+pGkRWPlF1fSjZIOknQocBtwqaTPNV1XB90m6bVNF7E3\n2H4KuEfSC5quZW+RdDZwDfDF0jQV+HpzFXWOpMMlLZd0fZmfJWlh03X1ldAYBts7qH5xVwFHAH9M\n9cfozxstrDMOLvv3FuAK28cCr2+4pk46FviRpHsl3SHpTkl3NF1UB00GNki6QdLq3lfTRXXQOcBx\nwA4A2xuB32+0os65nOqetOeX+Z8Bf9FYNQMY9fdpjDaS3gy8G3gJcAVwjO2tkg4A7gL+tsn6OmCi\npCOAtwN/1XQxe8HJTRewl32s6QL2st/ZfkISAJImAmPlvoHDbF8t6Xx4+ubmp5ouqq+Exp57K3Cx\n7e+1Ntp+bDQeSg7DBVSfdr5v+xZJLwI2NlxTx9i+X9LrgJm2vySpC3hu03V1iu3vNl3DXvZdSR8B\n9pf0BuB9wD81XFOn/FbS8yghKGkO8GizJe0uN/cNg6TDgd7z4jfb3tpkPVGfpCXAbOBI238g6fnA\nV20f13BpHVH+0Pwt8B+BSVSP3/mt7YMaLaxDysjFhcBJgKg+4FzmMfCHTNLRVP/vjgJ+AnQBZ9ge\nVadPExp7SNLbgM8CN1L90v4h8Je2r2myrk6R9Gngk8C/Ad8EXgF80Pb/bbSwDpF0O9VAhttsv7q0\n3WF7TIwSk9RN9WDPr1KF43zgD2yf32hhHSLpLcB1tn/XdC17QznddiTV35Z7bD/ZcEm7yYXwPfdR\n4LW2F9ieT/XtgmPpPPJJ5UL4acB9VNdu/rLRijrrifKptPcUwHMarqfjbPcAE2w/ZftLwNyma+qg\nNwE/k/RlSaeVP7JjQvlAun95KOvpwFXl6GNUSWjsuWf1OR31MGPrv2PvP8JTqU7bjLpzqm26WtIX\ngUPK8M1/Bi5tuKZOeqx8jcDt5V6iDzKGfj9t9w5C+SpwFnCvpMuarapjPmb7N+Wa24nAcmBpwzXt\nZsyk9Aj6pqS1wJVl/kzg+gbr6bRvlBvE/g14b7lQ/HjDNXWM7c+WC6g7qE4D/LXtdQ2X1UnvogqJ\nc4EPUn2J2VsbrajDbD9Z7mUwsD/Vp/L3NFtVR/SOlDoVuNT2dZI+2WRB/ck1jWEo51V7L5z+i+0x\ncXNRr3Jj36O2nyqnbw60/VDTdUU9kvYHXmB7JL/2eERIOoXqqQzHU11XvBr4lu2dDZbVEZK+QfXN\npG8Ajqb64Haz7Vc2WlgfCY2aJH3f9usk/YbqE45aFv87sB34jO0vNFJgh5T7Tf4H1R+dRZJmUo00\n+kbDpXVEy/+/Vo8C3cCHbG8a+ao6R9KbqAZqTLI9Q9KrgAtsv7nh0jpC0pXAVcD1Y+1iePm3Nxe4\n0/bGcr/Uy21/q+HSdpHQ6JAyvvqHto9supZ2SLoKuBWYb/uo8ov8Q9uvari0jpD0CWAz8PdUwX8m\n8GKqR6a81/bxzVXXPkm3AicAN7aMDrvT9subraxzxtqQd0kH2d5RjvB3Y3v7SNc0mDFzgaxpth+m\nOmTe173Y9qeBJ6G6aZFdj6r2dW+2/UXbv7G9w/Yy4GTbV1E9gmNf92Q/gxfGzCfDMsLoZuBtVE8t\nuEnSGc1W1ba/Lz9vpTrivbXl1d1UUQPJhfAOsv1g0zV0wBPlnHjvkNQXA2PpNMBjkt5O9ewwgDN4\n5kL/WPjjukHSnwITyqnF9wM/bLimTuod8r4VoAzU+Gee+f+5z7F9mqrnovyR7V80Xc9QcqQRfS2h\nuqlvmqSvADcAH262pI56B9UIo63AL8v0O0tQnttkYe2Q9OUyeS/wMqqgv5JqlNioe+hdG8bkkPdy\n79B1TddRR65pxG7K9Zk5VKel1tv+VcMlxRAk3UX1NOLrgf/ad/loOy8+XJI+Q/WUgt4h738C3GH7\nvOaq6gxJK4G/s31L07UMJqERu5E0BXghLacv+z6gcV9VTmecDUxn1/37s6Zq6gRJ7wfeC7yIatjm\n04uoPsi+qJHC9gJJb2XXIe//2GQ9nVLuj3oJcD/wW575fzeqHnGT0IhdSPoU1ae3DVRDiaH6xR0r\nQzZ/CPwL1UXGpx87bftrjRXVQZKW2n5v03XEnpP0wv7abd8/0rUMJqERu5B0D/CKsTYGvpek28fK\n8OHxZID7a+CZT+Nj5Sm+RwOvo9rXH9i+reGSdrPPX0CKjtsE/F7TRexF35D0xqaLiD1j+0DbB/Xz\nOnAMBcZfAyuB5wGHAV+S9NFmq9pdjjRiF5K+BrySatTU00cbtt/fWFEdVD6xPodq355kjH1SjX1X\nOcp/pe3Hy/z+wO2j7Ybh3KcRfa0urzHJ9oHlztuZwLObrieixf+j+p3svW9oP3Yd1DAq5EgjxhVJ\n7wE+AEwFbqcaWvxD2yc2WliMe5K+TvV4lHVU1zTeQHX3+2YYPUf7CY0AqucTMcgd0aNt2N9wlf18\nLdX9J6+S9FLgf9l+S8OlxTgnacFgy22vHKlaBpPTU9HrtPLznPKz9w7jdzI2Hq/R63Hbj0tC0n62\nfyppVJ0zjvFH0gSqb818R9O1DCWhEcAzY8ElvaH36ajFeZJuAxY3U1nHbZZ0CPB1YJ2kR6hupopo\nTPnumhdKmmT7iabrGUxCI/qSpONs/6DM/GfG0NBs239cJj8u6TvAwVTP2opo2ibgB5JWU90RDoDt\nzzVX0u4SGtHXQmCFpIOphqM+AuzTj9gYiO3vNl1DRIt7y+tZwIEN1zKgXAiPfpXQoJ/vZoiIcSyh\nEbuRdCrV47Wfvo/B9gXNVRQx9pXTpbv9QbZ9QgPlDCinp2IXkv4PcADV47Uvo/qSopsbLSpifPif\nLdPPBt4K7GyolgHlSCN2IekO269o+flc4Hrbf9h0bRHjjaSbbR/TdB2tcqQRffU+wuAxSc8HtgNH\nNFhPxLhQHm/T61nAbKrRfaNKQiP6+qdyH8NngNuozrFe2mxJEePCrVT/3kT1MM37qEYzjipjZvx9\ndMxPgafKlxJ9HlhPdSNcROxd5wGvsj2D6okMvwUea7ak3SU0oq+P2f6NpNcBJ1BdDF/acE0R48FH\nbe8Y7f/2EhrRV+9XoJ4KXGr7OmBSg/VEjBf7xL+9hEb0tUXSF6m+J3yNpP3I70nESNgn/u1lyG3s\nQtIBwFzgTtsbJR0BvNz2txouLWJM21f+7SU0IiKitlF36BMREaNXQiMiImpLaERERG0JjYiIqC2h\nERERtf1/4EfnAP+MudQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMXfE6ylmf2n",
        "colab_type": "code",
        "outputId": "803d783a-8b29-4f44-93d7-a7844e6ba854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "text_data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27383</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110083</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140764</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100071</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2837</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18231</th>\n",
              "      <td>i find myself frustrated with christians becau...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10714</th>\n",
              "      <td>i am one of those people who feels like going ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35177</th>\n",
              "      <td>i feel especially pleased about this as this h...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122177</th>\n",
              "      <td>i was struggling with these awful feelings and...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26723</th>\n",
              "      <td>i feel so enraged but helpless at the same time</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "27383   i feel awful about it too because it s my job ...  sadness\n",
              "110083                              im alone i feel awful  sadness\n",
              "140764  ive probably mentioned this before but i reall...      joy\n",
              "100071           i was feeling a little low few days back  sadness\n",
              "2837    i beleive that i am much more sensitive to oth...     love\n",
              "18231   i find myself frustrated with christians becau...     love\n",
              "10714   i am one of those people who feels like going ...      joy\n",
              "35177   i feel especially pleased about this as this h...      joy\n",
              "122177  i was struggling with these awful feelings and...      joy\n",
              "26723     i feel so enraged but helpless at the same time    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGbqP_dm5zV",
        "colab_type": "code",
        "outputId": "9017a837-cba9-404c-89e1-4b0472cc593e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_data.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(416809, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KX8YfRqmSn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0b17f3ea-9b15-4af8-8b3d-e219b08ffd34"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vAXfjJBah40",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yha3oqZLxJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data[\"token_size\"] = text_data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "text_data = text_data.loc[text_data['token_size'] < 70].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b-Nn5wxOCvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_list = text_data[\"text\"].values.tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxWQGibPLRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for i in words_list:\n",
        "  words.append(nltk.word_tokenize(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEfK-gBrapL0",
        "colab_type": "text"
      },
      "source": [
        "## Constructing dictionery for mapping words to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRMYPdvU6sv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEUq5i6SYzWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = ConstructVocab(words_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEgzoprWY_KB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "ebe6d685-8504-46f0-96dd-de539eca354b"
      },
      "source": [
        "inputs.vocab[0:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaaa',\n",
              " 'aaaaaaaaaaaaaaaaggghhhh',\n",
              " 'aaaaaaaaaaaaaaarrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrggggggggggggggggggggggggggggghhhhhhhhhhhhhh',\n",
              " 'aaaaaaaall',\n",
              " 'aaaaaaand',\n",
              " 'aaaaaand',\n",
              " 'aaaaah']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvRJVJ26Zbcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in words_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JUBnUBO-ISd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "78d0ebe3-9831-4285-d0bf-71d51397782f"
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[31288,\n",
              "  23285,\n",
              "  4481,\n",
              "  213,\n",
              "  33865,\n",
              "  67505,\n",
              "  5654,\n",
              "  33865,\n",
              "  56757,\n",
              "  43786,\n",
              "  34676,\n",
              "  67263,\n",
              "  26464,\n",
              "  29937,\n",
              "  32070,\n",
              "  1,\n",
              "  50692,\n",
              "  67263,\n",
              "  63949,\n",
              "  2386,\n",
              "  33865,\n",
              "  35118,\n",
              "  17317,\n",
              "  65045,\n",
              "  28764,\n",
              "  29654],\n",
              " [31695, 1913, 31288, 23285, 4481]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ByE4kkEnwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c97b28d-b209-442f-cf7b-8c5af0254672"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)  "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knxytlIvFNUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHjSBwAWHuBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KzVKg9xHw5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "21a73275-c438-412a-9450-28816e8c7e0e"
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([31288, 23285,  4481,   213, 33865, 67505,  5654, 33865, 56757,\n",
              "        43786, 34676, 67263, 26464, 29937, 32070,     1, 50692, 67263,\n",
              "        63949,  2386, 33865, 35118, 17317, 65045, 28764, 29654,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([31695,  1913, 31288, 23285,  4481,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFwGF1aH0a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(text_data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in text_data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXgb1DZCM6iS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "564e6c31-d439-4223-d103-5771cc9aafe1"
      },
      "source": [
        "target_tensor"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 1, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjBJ4ZxsM-sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "7a164592-3819-4bd5-f4a2-f38cfa654f21"
      },
      "source": [
        "text_data[0:2]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27383</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110083</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions  token_size\n",
              "27383   i feel awful about it too because it s my job ...  sadness          26\n",
              "110083                              im alone i feel awful  sadness           5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKLK_kptNJQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a158824-4055-4e4d-931b-93196937acc3"
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)\n",
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kksj7uiWNOQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ad303ab-54be-4d98-cb6c-765e39097e4f"
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sadness'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFQoAnj3NTd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3679ba3c-776a-4ede-8ff2-45d1bc29abe1"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333431, 333431, 41679, 41679, 41679, 41679)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-tVlL-fNlCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RI8tBbiNuo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su-O_-rqNxt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeQ295U9PwKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c0a3c4f-744a-4c4f-c192-aad06b0bdd4a"
      },
      "source": [
        "print(len(train_dataset))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dNY4N2rNz0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a8a79a6-d8e3-4ac7-b10f-8c1cc2106831"
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYpzu73nN2Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1miHD3PN5gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39jqITmtN8WZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "04af84f5-994d-41bd-9b49-3aaf08be390c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(\"Output size : \", output.size())\n",
        "print(device)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([69, 64])\n",
            "Output size :  torch.Size([64, 6])\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPOMgqw_N-aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClyQJ9QsOB6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78018e23-4772-43aa-c183-b77133eae8a8"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 500 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.0125\n",
            "Epoch 1 Batch 500 Val. Loss 0.0165\n",
            "Epoch 1 Batch 1000 Val. Loss 0.0122\n",
            "Epoch 1 Batch 1500 Val. Loss 0.0152\n",
            "Epoch 1 Batch 2000 Val. Loss 0.0226\n",
            "Epoch 1 Batch 2500 Val. Loss 0.0347\n",
            "Epoch 1 Batch 3000 Val. Loss 0.0169\n",
            "Epoch 1 Batch 3500 Val. Loss 0.0068\n",
            "Epoch 1 Batch 4000 Val. Loss 0.0099\n",
            "Epoch 1 Batch 4500 Val. Loss 0.0095\n",
            "Epoch 1 Batch 5000 Val. Loss 0.0238\n",
            "Epoch 1 Loss 0.0211 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 246.38176822662354 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.0158\n",
            "Epoch 2 Batch 500 Val. Loss 0.0123\n",
            "Epoch 2 Batch 1000 Val. Loss 0.0230\n",
            "Epoch 2 Batch 1500 Val. Loss 0.0199\n",
            "Epoch 2 Batch 2000 Val. Loss 0.0083\n",
            "Epoch 2 Batch 2500 Val. Loss 0.0232\n",
            "Epoch 2 Batch 3000 Val. Loss 0.0181\n",
            "Epoch 2 Batch 3500 Val. Loss 0.0067\n",
            "Epoch 2 Batch 4000 Val. Loss 0.0160\n",
            "Epoch 2 Batch 4500 Val. Loss 0.0369\n",
            "Epoch 2 Batch 5000 Val. Loss 0.0285\n",
            "Epoch 2 Loss 0.0194 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 246.70567417144775 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.0108\n",
            "Epoch 3 Batch 500 Val. Loss 0.0109\n",
            "Epoch 3 Batch 1000 Val. Loss 0.0176\n",
            "Epoch 3 Batch 1500 Val. Loss 0.0318\n",
            "Epoch 3 Batch 2000 Val. Loss 0.0141\n",
            "Epoch 3 Batch 2500 Val. Loss 0.0074\n",
            "Epoch 3 Batch 3000 Val. Loss 0.0024\n",
            "Epoch 3 Batch 3500 Val. Loss 0.0177\n",
            "Epoch 3 Batch 4000 Val. Loss 0.0168\n",
            "Epoch 3 Batch 4500 Val. Loss 0.0234\n",
            "Epoch 3 Batch 5000 Val. Loss 0.0178\n",
            "Epoch 3 Loss 0.0183 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 246.2387237548828 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0230\n",
            "Epoch 4 Batch 500 Val. Loss 0.0117\n",
            "Epoch 4 Batch 1000 Val. Loss 0.0160\n",
            "Epoch 4 Batch 1500 Val. Loss 0.0213\n",
            "Epoch 4 Batch 2000 Val. Loss 0.0087\n",
            "Epoch 4 Batch 2500 Val. Loss 0.0136\n",
            "Epoch 4 Batch 3000 Val. Loss 0.0131\n",
            "Epoch 4 Batch 3500 Val. Loss 0.0220\n",
            "Epoch 4 Batch 4000 Val. Loss 0.0323\n",
            "Epoch 4 Batch 4500 Val. Loss 0.0109\n",
            "Epoch 4 Batch 5000 Val. Loss 0.0281\n",
            "Epoch 4 Loss 0.0177 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 246.06436133384705 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0145\n",
            "Epoch 5 Batch 500 Val. Loss 0.0173\n",
            "Epoch 5 Batch 1000 Val. Loss 0.0236\n",
            "Epoch 5 Batch 1500 Val. Loss 0.0086\n",
            "Epoch 5 Batch 2000 Val. Loss 0.0117\n",
            "Epoch 5 Batch 2500 Val. Loss 0.0042\n",
            "Epoch 5 Batch 3000 Val. Loss 0.0159\n",
            "Epoch 5 Batch 3500 Val. Loss 0.0250\n",
            "Epoch 5 Batch 4000 Val. Loss 0.0091\n",
            "Epoch 5 Batch 4500 Val. Loss 0.0263\n",
            "Epoch 5 Batch 5000 Val. Loss 0.0212\n",
            "Epoch 5 Loss 0.0172 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 245.48170971870422 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0098\n",
            "Epoch 6 Batch 500 Val. Loss 0.0212\n",
            "Epoch 6 Batch 1000 Val. Loss 0.0134\n",
            "Epoch 6 Batch 1500 Val. Loss 0.0171\n",
            "Epoch 6 Batch 2000 Val. Loss 0.0212\n",
            "Epoch 6 Batch 2500 Val. Loss 0.0134\n",
            "Epoch 6 Batch 3000 Val. Loss 0.0150\n",
            "Epoch 6 Batch 3500 Val. Loss 0.0175\n",
            "Epoch 6 Batch 4000 Val. Loss 0.0051\n",
            "Epoch 6 Batch 4500 Val. Loss 0.0243\n",
            "Epoch 6 Batch 5000 Val. Loss 0.0144\n",
            "Epoch 6 Loss 0.0170 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 245.56158447265625 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0097\n",
            "Epoch 7 Batch 500 Val. Loss 0.0052\n",
            "Epoch 7 Batch 1000 Val. Loss 0.0162\n",
            "Epoch 7 Batch 1500 Val. Loss 0.0141\n",
            "Epoch 7 Batch 2000 Val. Loss 0.0046\n",
            "Epoch 7 Batch 2500 Val. Loss 0.0247\n",
            "Epoch 7 Batch 3000 Val. Loss 0.0131\n",
            "Epoch 7 Batch 3500 Val. Loss 0.0110\n",
            "Epoch 7 Batch 4000 Val. Loss 0.0071\n",
            "Epoch 7 Batch 4500 Val. Loss 0.0180\n",
            "Epoch 7 Batch 5000 Val. Loss 0.0504\n",
            "Epoch 7 Loss 0.0166 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 245.48911094665527 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0107\n",
            "Epoch 8 Batch 500 Val. Loss 0.0300\n",
            "Epoch 8 Batch 1000 Val. Loss 0.0180\n",
            "Epoch 8 Batch 1500 Val. Loss 0.0146\n",
            "Epoch 8 Batch 2000 Val. Loss 0.0305\n",
            "Epoch 8 Batch 2500 Val. Loss 0.0250\n",
            "Epoch 8 Batch 3000 Val. Loss 0.0121\n",
            "Epoch 8 Batch 3500 Val. Loss 0.0244\n",
            "Epoch 8 Batch 4000 Val. Loss 0.0219\n",
            "Epoch 8 Batch 4500 Val. Loss 0.0183\n",
            "Epoch 8 Batch 5000 Val. Loss 0.0135\n",
            "Epoch 8 Loss 0.0165 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 245.1991217136383 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0111\n",
            "Epoch 9 Batch 500 Val. Loss 0.0146\n",
            "Epoch 9 Batch 1000 Val. Loss 0.0112\n",
            "Epoch 9 Batch 1500 Val. Loss 0.0080\n",
            "Epoch 9 Batch 2000 Val. Loss 0.0112\n",
            "Epoch 9 Batch 2500 Val. Loss 0.0187\n",
            "Epoch 9 Batch 3000 Val. Loss 0.0111\n",
            "Epoch 9 Batch 3500 Val. Loss 0.0297\n",
            "Epoch 9 Batch 4000 Val. Loss 0.0236\n",
            "Epoch 9 Batch 4500 Val. Loss 0.0139\n",
            "Epoch 9 Batch 5000 Val. Loss 0.0165\n",
            "Epoch 9 Loss 0.0164 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 244.66346216201782 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0110\n",
            "Epoch 10 Batch 500 Val. Loss 0.0093\n",
            "Epoch 10 Batch 1000 Val. Loss 0.0153\n",
            "Epoch 10 Batch 1500 Val. Loss 0.0205\n",
            "Epoch 10 Batch 2000 Val. Loss 0.0211\n",
            "Epoch 10 Batch 2500 Val. Loss 0.0145\n",
            "Epoch 10 Batch 3000 Val. Loss 0.0090\n",
            "Epoch 10 Batch 3500 Val. Loss 0.0177\n",
            "Epoch 10 Batch 4000 Val. Loss 0.0070\n",
            "Epoch 10 Batch 4500 Val. Loss 0.0354\n",
            "Epoch 10 Batch 5000 Val. Loss 0.0218\n",
            "Epoch 10 Loss 0.0163 -- Train Acc. 93.0000 -- Val Acc. 93.0000\n",
            "Time taken for 1 epoch 244.67711997032166 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEm63ZmhrNET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1ed9f15b-a079-45f0-f98f-ad9cc87d7c0c"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(75296, 256)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}