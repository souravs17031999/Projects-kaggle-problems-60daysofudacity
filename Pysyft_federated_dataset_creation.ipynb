{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pysyft_federated_dataset_creation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/Projects-kaggle-problems-60daysofudacity/blob/master/Pysyft_federated_dataset_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5z-S895gsAU",
        "colab_type": "text"
      },
      "source": [
        "# OBJECTIVE : To create custom federated datasets and dataloader in PySyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuesWRLbyUd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM8LDyci0NeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import all required packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4zCK90Y2T-K",
        "colab_type": "code",
        "outputId": "0331870b-c578-4758-f884-c180566e347a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# creating virtual workers\n",
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "# let's create two virtual workers who will hold the data while training the model locally\n",
        "bob = sy.VirtualWorker(hook, id = \"bob\")\n",
        "alice = sy.VirtualWorker(hook, id = \"alice\")\n",
        "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 04:16:33.146131 139690531305344 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0825 04:16:33.159694 139690531305344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68dOKwZX2Wuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating inputs and targets (labels)\n",
        "inputs = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghwZQrNIqw2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use BaseDataset class which takes data, targets as args\n",
        "# This class has .data attribute , .targets attribute to make it able to manipulate\n",
        "# It has .send attibute to send to workers\n",
        "bob_train_dataset = sy.BaseDataset(inputs[:2], target[:2]).send(bob)\n",
        "alice_train_dataset = sy.BaseDataset(inputs[2:], target[2:]).send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSQSW5qzJ6tm",
        "colab_type": "code",
        "outputId": "009dc9fa-93ca-4180-f9fe-d86c4cd62e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(bob_train_dataset.data)\n",
        "print(bob_train_dataset.targets)\n",
        "print(alice_train_dataset.data)\n",
        "print(alice_train_dataset.targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor>[PointerTensor | me:55617970640 -> bob:12076290068]\n",
            "Tensor>[PointerTensor | me:38801454586 -> bob:96929184740]\n",
            "Tensor>[PointerTensor | me:93238096976 -> alice:11082570616]\n",
            "Tensor>[PointerTensor | me:59498225150 -> alice:27819445055]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWrBg4CNsZ2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FederatedDataset class takes a list of remote datasets as args\n",
        "# It takes the datasets already sent to remote workers\n",
        "# This also acts as input to FederatedDataLoader\n",
        "federated_train_dataset = sy.FederatedDataset([bob_train_dataset, alice_train_dataset])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6eV3fLhKvvx",
        "colab_type": "code",
        "outputId": "aee5705d-cf4d-4332-d904-32352dc93a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(federated_train_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FederatedDataset\n",
            "    Distributed accross: bob, alice\n",
            "    Number of datapoints: 4\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yestBjo2sihN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This FederatedDataLoader class iterates over the objects created by FederatedDataset class\n",
        "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlt38cUZsnM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs, labels = next(iter(federated_train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFXXrfBlsvJv",
        "colab_type": "code",
        "outputId": "0101ad45-ebe1-48d1-e8fc-fb0eb7913e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTUHKJ5QswFn",
        "colab_type": "code",
        "outputId": "8d7e53e8-91bc-4489-fba6-fc6f27d08c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}