{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPproject_emotion_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/Projects-kaggle-problems-60daysofudacity/blob/master/NLPproject_emotion_recognition_fedlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgDvFNfInAKY",
        "colab_type": "text"
      },
      "source": [
        "# Project : NLP Emotion recognition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKe37pq4nH0k",
        "colab_type": "text"
      },
      "source": [
        "## Importing all the packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGCvGqgNOPAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "import torch.utils.data as data_utils\n",
        "from PIL import Image, ImageFile\n",
        "import json\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXJZHqKAjTLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uiC_l_9nM7D",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset from the source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXhyhZsgjZ3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GzeUNKZlENi",
        "colab_type": "code",
        "outputId": "5b6a30a1-0421-4176-a1b2-00a7968ef599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2L6wF2mPVc",
        "colab_type": "code",
        "outputId": "d4563404-6348-407b-b026-fa915beb879e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# load data\n",
        "text_data = load_from_pickle(directory=\"/content/drive/My Drive/train.pkl\")\n",
        "text_data.emotion.value_counts().plot.bar()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7278571470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEbCAYAAAAxukhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMXfE6ylmf2n",
        "colab_type": "code",
        "outputId": "1a8d5ca6-c823-4c51-8362-2af605837a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "text_data.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>how the fu k who the heck moved my fridge shou...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>so my indian uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>uk i asked for my parcel to be delivered to a ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>don t join they put the phone down on you talk...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10005</td>\n",
              "      <td>my blood is boiling</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10006</td>\n",
              "      <td>when you ve still got a whole season of wentwo...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10007</td>\n",
              "      <td>uk why does tracking show my equipment deliver...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10008</td>\n",
              "      <td>legit why i am so furious with him people are ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10009</td>\n",
              "      <td>how is it suppose to work if you do that wtf d...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                             tweets emotion  intensity\n",
              "0  10000  how the fu k who the heck moved my fridge shou...   anger      0.938\n",
              "1  10001  so my indian uber driver just called someone t...   anger      0.896\n",
              "2  10002  uk i asked for my parcel to be delivered to a ...   anger      0.896\n",
              "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
              "4  10004  don t join they put the phone down on you talk...   anger      0.896\n",
              "5  10005                                my blood is boiling   anger      0.875\n",
              "6  10006  when you ve still got a whole season of wentwo...   anger      0.875\n",
              "7  10007  uk why does tracking show my equipment deliver...   anger      0.875\n",
              "8  10008  legit why i am so furious with him people are ...   anger      0.875\n",
              "9  10009  how is it suppose to work if you do that wtf d...   anger      0.875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGbqP_dm5zV",
        "colab_type": "code",
        "outputId": "7a7bf0a3-d941-46ac-eb35-d2024d85f8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46969, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo8fJ80eiB8q",
        "colab_type": "code",
        "outputId": "54205f09-6580-4a83-c7ae-d45c5ff0181f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text_data['tweets'][0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KX8YfRqmSn0",
        "colab_type": "code",
        "outputId": "bc8ddcd3-d63e-4fbb-91af-eb42ec42637c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-GEu0iVyDzc",
        "colab_type": "text"
      },
      "source": [
        "## Installing pysyft "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l-mDxJmgJ_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install syft\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDRv85BryIK9",
        "colab_type": "text"
      },
      "source": [
        "## Creating virtual workers and hooking them up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkK_n68ChlWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "adeb5a7c-7c77-4f12-d3fb-019ac6170bc8"
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "# let's create two virtual workers who will hold the data while training the model locally\n",
        "bob = sy.VirtualWorker(hook, id = \"bob\")\n",
        "alice = sy.VirtualWorker(hook, id = \"alice\")\n",
        "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 15:31:21.550872 140131847350144 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0818 15:31:21.570211 140131847350144 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWV6qpK3iJyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This arguments class is simply defining all the hyperparameters of the model we are going to train on\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64 # batch size for training\n",
        "        self.test_batch_size = 64 # bacth size for testing \n",
        "        self.epochs = 10 # no of epochs\n",
        "        self.lr = 0.01  # setting learning rate\n",
        "        self.momentum = 0.5 \n",
        "        self.no_cuda = False  \n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vAXfjJBah40",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing (tokenizing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yha3oqZLxJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data[\"token_size\"] = text_data[\"tweets\"].apply(lambda x: len(x.split(' ')))\n",
        "text_data = text_data.loc[text_data['token_size'] < 70].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b-Nn5wxOCvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_list = text_data[\"tweets\"].values.tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxWQGibPLRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for i in words_list:\n",
        "  words.append(nltk.word_tokenize(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEfK-gBrapL0",
        "colab_type": "text"
      },
      "source": [
        "## Constructing dictionery for mapping words to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRMYPdvU6sv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEUq5i6SYzWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = ConstructVocab(words_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEgzoprWY_KB",
        "colab_type": "code",
        "outputId": "fcbd6225-3b7c-45a1-b48e-947e8bf9f69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "inputs.vocab[0:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaron',\n",
              " 'aateam',\n",
              " 'ab',\n",
              " 'abby',\n",
              " 'aber',\n",
              " 'aberdeen',\n",
              " 'abhijit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvRJVJ26Zbcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in words_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JUBnUBO-ISd",
        "colab_type": "code",
        "outputId": "010bd045-a105-4152-d4bd-fcb531fd1b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3420,\n",
              "  7358,\n",
              "  2781,\n",
              "  3870,\n",
              "  8087,\n",
              "  7358,\n",
              "  3269,\n",
              "  4695,\n",
              "  4748,\n",
              "  2750,\n",
              "  6602,\n",
              "  3479,\n",
              "  3968,\n",
              "  7358,\n",
              "  4012,\n",
              "  2033,\n",
              "  280,\n",
              "  4308],\n",
              " [6770,\n",
              "  4748,\n",
              "  3582,\n",
              "  7672,\n",
              "  2080,\n",
              "  3859,\n",
              "  1054,\n",
              "  6807,\n",
              "  7358,\n",
              "  4755,\n",
              "  8170,\n",
              "  3503,\n",
              "  3479,\n",
              "  7977,\n",
              "  7203,\n",
              "  3557,\n",
              "  1,\n",
              "  4701,\n",
              "  7831,\n",
              "  3479,\n",
              "  1698,\n",
              "  3226,\n",
              "  3847,\n",
              "  5233,\n",
              "  1955]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ByE4kkEnwD",
        "colab_type": "code",
        "outputId": "20493c0d-457e-4739-df69-cd3f3fdf5a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knxytlIvFNUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHjSBwAWHuBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KzVKg9xHw5a",
        "colab_type": "code",
        "outputId": "0b9c855d-3da4-42fb-9468-3b589453e8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3420, 7358, 2781, 3870, 8087, 7358, 3269, 4695, 4748, 2750, 6602,\n",
              "        3479, 3968, 7358, 4012, 2033,  280, 4308,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " array([6770, 4748, 3582, 7672, 2080, 3859, 1054, 6807, 7358, 4755, 8170,\n",
              "        3503, 3479, 7977, 7203, 3557,    1, 4701, 7831, 3479, 1698, 3226,\n",
              "        3847, 5233, 1955,    0,    0,    0,    0,    0,    0,    0,    0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOaE-3aNyat-",
        "colab_type": "text"
      },
      "source": [
        "## converting emotions to one hot encoded list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFwGF1aH0a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(text_data.emotion.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in text_data[['emotion']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXgb1DZCM6iS",
        "colab_type": "code",
        "outputId": "80886e79-ce57-4bc9-87d8-15342b5ec766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "target_tensor"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjBJ4ZxsM-sp",
        "colab_type": "code",
        "outputId": "4041e3a8-0720-4e72-f660-647f3793aec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "text_data[0:3]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>how the fu k who the heck moved my fridge shou...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>so my indian uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>uk i asked for my parcel to be delivered to a ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... token_size\n",
              "0  10000  ...         18\n",
              "1  10001  ...         25\n",
              "2  10002  ...         19\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ljb1Jyu9ve",
        "colab_type": "code",
        "outputId": "6052d8a4-fd2c-4cb0-a772-d3b29fb97287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text_data[\"emotion\"]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        anger\n",
              "1        anger\n",
              "2        anger\n",
              "3        anger\n",
              "4        anger\n",
              "5        anger\n",
              "6        anger\n",
              "7        anger\n",
              "8        anger\n",
              "9        anger\n",
              "10       anger\n",
              "11       anger\n",
              "12       anger\n",
              "13       anger\n",
              "14       anger\n",
              "15       anger\n",
              "16       anger\n",
              "17       anger\n",
              "18       anger\n",
              "19       anger\n",
              "20       anger\n",
              "21       anger\n",
              "22       anger\n",
              "23       anger\n",
              "24       anger\n",
              "25       anger\n",
              "26       anger\n",
              "27       anger\n",
              "28       anger\n",
              "29       anger\n",
              "         ...  \n",
              "46939      joy\n",
              "46940      joy\n",
              "46941      joy\n",
              "46942      joy\n",
              "46943      joy\n",
              "46944      joy\n",
              "46945      joy\n",
              "46946      joy\n",
              "46947      joy\n",
              "46948      joy\n",
              "46949      joy\n",
              "46950      joy\n",
              "46951      joy\n",
              "46952      joy\n",
              "46953      joy\n",
              "46954      joy\n",
              "46955      joy\n",
              "46956      joy\n",
              "46957      joy\n",
              "46958      joy\n",
              "46959      joy\n",
              "46960      joy\n",
              "46961      joy\n",
              "46962      joy\n",
              "46963      joy\n",
              "46964      joy\n",
              "46965      joy\n",
              "46966      joy\n",
              "46967      joy\n",
              "46968      joy\n",
              "Name: emotion, Length: 46969, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKLK_kptNJQg",
        "colab_type": "code",
        "outputId": "84d64bdd-af28-4c0a-ce85-ec9950c9e3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)\n",
        "get_emotion(target_tensor[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kksj7uiWNOQr",
        "colab_type": "code",
        "outputId": "2fdcb0e2-133b-48e0-d977-d31ff1c4112e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'sadness', 3: 'joy'}\n",
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anger'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2n7vFhyx8-3",
        "colab_type": "text"
      },
      "source": [
        "## Now , we are ready with our input data to model , now we are splitting dataset into training , validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFQoAnj3NTd0",
        "colab_type": "code",
        "outputId": "082443d3-db15-4e7c-e642-3225ff967268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "print(f\"training length: {len(input_tensor_train)}\")\n",
        "print(f\"training target length: {len(target_tensor_train)}\")\n",
        "print(f\"validation length: {len(input_tensor_val)}\")\n",
        "print(f\"validation target length: {len(target_tensor_val)}\")\n",
        "print(f\"testing length: {len(input_tensor_test)}\")\n",
        "print(f\"testing target length: {len(target_tensor_test)}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training length: 37575\n",
            "training target length: 37575\n",
            "validation length: 4697\n",
            "validation target length: 4697\n",
            "testing length: 4697\n",
            "testing target length: 4697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-tVlL-fNlCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = args.batch_size\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14-j0lJhyo5a",
        "colab_type": "text"
      },
      "source": [
        "## Defining custom dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RI8tBbiNuo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z1AOr18Vt3pI",
        "colab": {}
      },
      "source": [
        "input_tensor_train, target_tensor_train = torch.tensor(input_tensor_train), torch.tensor(target_tensor_train) # converting train data list to tensors to it work on pysyft functions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeNcpggiyur2",
        "colab_type": "text"
      },
      "source": [
        "## Sending our training dataset to workers - bob and alice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5QLy8VIt8Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_idx = int(len(target_tensor_train)/2)\n",
        "\n",
        "# Sending train datasets to virtual workers\n",
        "bob_train_dataset = sy.BaseDataset(input_tensor_train[:train_idx], \n",
        "                                  target_tensor_train[:train_idx]).send(bob)\n",
        "alice_train_dataset = sy.BaseDataset(input_tensor_train[train_idx:], \n",
        "                                    target_tensor_train[train_idx:]).send(alice)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yVaMlxnvvtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating federated dataset \n",
        "federated_train_dataset = sy.FederatedDataset([bob_train_dataset, alice_train_dataset])\n",
        "# creating federated loader to iterate over data from both workers\n",
        "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, \n",
        "                                                shuffle=True, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su-O_-rqNxt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYpzu73nN2Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1miHD3PN5gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39jqITmtN8WZ",
        "colab_type": "code",
        "outputId": "6bac1922-3dee-4af7-8062-4a79a92c0a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(val_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), device)\n",
        "print(\"Output size : \", output.size())\n",
        "print(device)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([33, 64])\n",
            "Output size :  torch.Size([64, 4])\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fRJgPj0U4dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "99a36241-894a-4b96-b358-aabc1798011a"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(8347, 256)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPOMgqw_N-aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adadelta(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClyQJ9QsOB6O",
        "colab_type": "code",
        "outputId": "38351a41-17fb-413d-e3ca-105580313753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "EPOCHS = 50\n",
        "valid_loss_min = np.inf\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ)) in enumerate(federated_train_loader):\n",
        "        model.send(inp.location)\n",
        "        loss = 0\n",
        "        predictions = model(inp.permute(1 ,0).to(device), device)   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions).get().item()\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        model.get()\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    if total_loss / TRAIN_N_BATCH <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,total_loss / TRAIN_N_BATCH))\n",
        "        valid_loss_min = total_loss / TRAIN_N_BATCH\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-54fb1c69dd0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-6adc35467436>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# max_len X batch_size X hidden_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVNldRc_6GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}