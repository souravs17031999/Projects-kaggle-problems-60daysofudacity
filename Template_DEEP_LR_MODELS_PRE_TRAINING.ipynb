{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Template_DEEP_LR_MODELS_PRE_TRAINING.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/kaggle-problems-60daysofudacity/blob/master/Template_DEEP_LR_MODELS_PRE_TRAINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBXpOQIVOLbl",
        "colab_type": "text"
      },
      "source": [
        "# Template for using in deep learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m2_RrHxOZ6Q",
        "colab_type": "text"
      },
      "source": [
        "### Used for classification problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x18552cyOe1A",
        "colab_type": "text"
      },
      "source": [
        "### KAGGLE WORK (IF REQUIRED)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmYvfeLaOlRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"souravs17031999\",\"key\":\"c0dfc674730fdb391ccd28e80943c438\"} # copy the API from kaggle.json downloaded from kaggle account\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dansbecker/hot-dog-not-hot-dog   # sample for downloading the dataset directly from kaggle API (can be copied from dataset kaggle page)\n",
        "!unzip ./{/content}/datasets/dansbecker/hot-dog-not-hot-dog/hot-dog-not-hot-dog.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gdUgRAnwm2V",
        "colab_type": "text"
      },
      "source": [
        "### Downloading from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLQNX2Icwlkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/SayedMaheen/sg_PlanetEarth/archive/master.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB5ybtcgPXpp",
        "colab_type": "text"
      },
      "source": [
        "## Importing drive so that we can save the checkpoint.pt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqABhA4XPy-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/drive/My Drive/{model_save_name}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHRMNZ7fEa5T",
        "colab_type": "text"
      },
      "source": [
        "## Let's get started by first importing all the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaxgFuSYPGEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import json\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g0O_Nu2QC6s",
        "colab_type": "text"
      },
      "source": [
        "## IMPORTING DATASET AND LOADING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSCRr6OLPivw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SETTING THE DIRECTORIES\n",
        "train_dir = 'train'\n",
        "test_dir = 'test'\n",
        "\n",
        "# APPLYING THE APPROPRIATE TRANSFORMS\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(),transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "# IMPORTING / DOWNLOADING THE DATASET\n",
        "train_data = datasets.ImageFolder(train_dir , transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "# DIVIDING TRAINING SET INTO TRAIN SET AND VALIDATION SET\n",
        "valid_size = 0.2\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# SAMPLING \n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# LOADING WITH DATA AUGMENTED\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64,sampler=train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
        "\n",
        "print(f\"training examples contain : {len(train_data)}\")\n",
        "print(f\"testing examples contain : {len(test_data)}\")\n",
        "\n",
        "print(len(trainloader))\n",
        "print(len(validloader))\n",
        "print(len(testloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORqJZdo_SzrJ",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the dataset completely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWljicORS60K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD ONE BATCH OF TESTING SET TO CHECK THE IMAGES AND THEIR LABELS\n",
        "images, labels = next(iter(testloader))\n",
        "\n",
        "# Checking shape of image\n",
        "print(f\"Image shape : {images.shape}\")\n",
        "print(f\"Label shape : {labels.shape}\")\n",
        "\n",
        "class_names = train_data.classes\n",
        "\n",
        "# denormalizing images\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "# plotting the images of loaded batch with given fig size and frame data    \n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "grid = torchvision.utils.make_grid(images, nrow = 20, padding = 2)\n",
        "plt.figure(figsize = (20, 20))  \n",
        "plt.imshow(np.transpose(grid, (1, 2, 0)))   \n",
        "print('labels:', labels)    \n",
        "\n",
        "# Printing normalized images\n",
        "images, labels = next(iter(testloader))\n",
        "out = torchvision.utils.make_grid(images)\n",
        "imshow(out, title=[class_names[x] for x in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BywklzV4T6vI",
        "colab_type": "text"
      },
      "source": [
        "## Checking for GPU enabled or not "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsd9zphATBu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuDTMxa_T-7N",
        "colab_type": "text"
      },
      "source": [
        "## DEFINING THE MODEL ARCHITECHTURE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnW1qWA6V7W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining device \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# downloading model\n",
        "model = models.resnet152(pretrained=True)  # if used inception , then use image size 299*299 otherwise 224*224 and use : model_ft.aux_logits=False to switch off auxiliary lyers\n",
        "# setting firstly classifier only for training \n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  \n",
        "# set inputs and output classes\n",
        "num_ftrs = model.fc.in_features\n",
        "out_ftrs = 2\n",
        "  \n",
        "model.fc = nn.Sequential(nn.Linear(num_ftrs, 512),nn.ReLU(),nn.Linear(512,out_ftrs),nn.LogSoftmax(dim=1))\n",
        "# defining the loss function \n",
        "criterion = nn.NLLLoss()\n",
        "  \n",
        "# defining the optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.fc.parameters()) , lr = 0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "# sending the model to device - GPU OR CPU\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjiRAPnKWyEt",
        "colab_type": "text"
      },
      "source": [
        "## TRAINING AND VALIDATION LOOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZTccMuQWpyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_test(e):\n",
        "    epochs = e\n",
        "    train_losses , test_losses = [] , []\n",
        "    valid_loss_min = np.Inf \n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "      running_loss = 0\n",
        "      batch = 0\n",
        "      scheduler.step()\n",
        "      for images , labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        batch += 1\n",
        "        print(f\" epoch {epoch + 1} batch {batch} completed\")\n",
        "      test_loss = 0\n",
        "      accuracy = 0\n",
        "      with torch.no_grad():\n",
        "        model.eval() \n",
        "        for images , labels in validloader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          logps = model(images) \n",
        "          test_loss += criterion(logps,labels) \n",
        "          ps = torch.exp(logps)\n",
        "          top_p , top_class = ps.topk(1,dim=1)\n",
        "          equals = top_class == labels.view(*top_class.shape)\n",
        "          accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "      train_losses.append(running_loss/len(trainloader))\n",
        "      test_losses.append(test_loss/len(validloader))\n",
        "      print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\"Valid Loss: {:.3f}.. \".format(test_loss/len(validloader)),\n",
        "        \"Valid Accuracy: {:.3f}\".format(accuracy/len(validloader)))\n",
        "      model.train() \n",
        "      if test_loss/len(validloader) <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,test_loss/len(validloader))) \n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model': model,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': valid_loss_min\n",
        "            }, path)\n",
        "        valid_loss_min = test_loss/len(validloader)    \n",
        "    print(f\"Best validation accuracy : {accuracy/len(validloader)}\")\n",
        "    print(f\"Best loss obtained : {valid_loss_min}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2mA6hXgXUYz",
        "colab_type": "text"
      },
      "source": [
        "## LOADING THE MODEL FOR RESUME TRAINING OR FOR INFERENCE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkuuxfB2XcbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(path):\n",
        "  checkpoint = torch.load(path)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FAZcVovXh7q",
        "colab_type": "text"
      },
      "source": [
        "## TESTING THE MODEL ON UNSEEN DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yedz9wZsXhZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = 0\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    p_labels = []\n",
        "    img_ids = []\n",
        "    i = 0\n",
        "    for inputs, labels in testloader:\n",
        "        i += 1\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        temp_acc = torch.sum(preds == labels.data)\n",
        "        accuracy += temp_acc\n",
        "        p_labels.append(preds)\n",
        "    # getting ids of file images    \n",
        "    for dir in os.listdir(test_dir):\n",
        "        for file in os.listdir(os.path.join(test_dir, dir)):\n",
        "            img_id = os.path.splitext(file)[0]\n",
        "            img_ids.append(img_id)\n",
        "    print('Accuracy =====>>', accuracy.item()/len(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE_FRlLaRqWD",
        "colab_type": "text"
      },
      "source": [
        "### Let's frame our dataset using pandas in format file id , pred labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8ogDW2kaDDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting our predictions as py list \n",
        "pred = []\n",
        "for i in p_labels:\n",
        "  for j in i:\n",
        "    pred.append(j.item())\n",
        "\n",
        "submission = pd.DataFrame({'Id': img_ids,'Predicted': pred})\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYcE4dflg6d1",
        "colab_type": "text"
      },
      "source": [
        "### EXTRA CODES TO MODIFY ABOVE FUNCTIONALITIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TpeXf7Kg6MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to unfreeze more layers \n",
        "for name,child in model.named_children():\n",
        "  if name in ['layer1','layer2','layer3','layer4','fc']:\n",
        "    print(name + 'is unfrozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "    print(name + 'is frozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIi4kNZ_hJPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use this when unfrozen more layers\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdncfOrlhQhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# after loading, printing state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aUUI0QKhjyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for checking which layers are open now \n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp9uZ6bFP52X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layer (sees 32x32x3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # convolutional layer (sees 16x16x16 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        # convolutional layer (sees 8x8x32 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # linear layer (64 * 4 * 4 -> 500)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
        "        # linear layer (500 -> 10)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F80OHqiJEnhk",
        "colab_type": "text"
      },
      "source": [
        "### for visulaizing accuracy and losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bhw8RYgErY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}